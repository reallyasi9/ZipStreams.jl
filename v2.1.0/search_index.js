var documenterSearchIndex = {"docs":
[{"location":"sinks/#Sinks:-Write-only-Streams-of-Data","page":"Writing to Sinks","title":"Sinks: Write-only Streams of Data","text":"","category":"section"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"CurrentModule = ZipStreams","category":"page"},{"location":"sinks/#Creating-archives-and-writing-files-with-zipsink","page":"Writing to Sinks","title":"Creating archives and writing files with zipsink","text":"","category":"section"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"You can wrap any IO object that supports writing bytes (any type that implements unsafe_write(::T, ::Ptr{UInt8}, ::UInt)) in a special ZIP archive writer with the zipsink function. The function will return an object that allows creating and writing files within the archive. You can then call open(sink, filename) using the returned object to create a new file in the archive and begin writing to it with standard IO functions.","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"This example creates a new ZIP archive file on disk, creates a new file within the archive, writes data to the file, then closes the file and archive:","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"using ZipStreams\n\nio = open(\"new-archive.zip\", \"w\")\nsink = zipsink(io)\nf = open(sink, \"hello.txt\")\nwrite(f, \"Hello, Julia!\")\nclose(f)\nclose(sink)","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"Convenience methods are included that create a new file on disk by passing a file name to zipsink instead of an IO object and that run a unary function so that zipsink can be used with a do ... end block. In addition, the open(sink, filename) method can also be used with a do ... end block, as this example shows:","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"using ZipStreams\n\nzipsink(\"new-archive.zip\") do sink  # create a new archive on disk and truncate it\n    open(sink, \"hello.txt\") do f  # create a new file in the archive\n        write(f, \"Hello, Julia!\")\n    end  # automatically write a Data Descriptor to the archive and close the file\nend  # automatically write the Central Directory and close the archive","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"Note that the IO method does not automatically close the IO object after the do block ends. The caller of that signature is responsible for the lifetime of the IO object. The IO object can be closed before the end of the do block by calling close on the sink. Additional writes to a closed sink will cause an ArgumentError to be thrown, but closing a closed sink is a noop, as these examples show:","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"using ZipStreams\n\nio = IOBuffer()\nzipsink(io) do sink\n    open(sink, \"hello.txt\") do f\n        write(f, \"Hello, Julia!\")\n    end\nend\n@assert isopen(io) == true\n\nzipsink(io) do sink\n    open(sink, \"goodbye.txt\") do f\n        write(f, \"Good bye, Julia!\")\n    end\n    close(sink)\nend\n@assert isopen(io) == false","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"Because the data are streamed to the archive, you can only have one file open for writing at a time in a given archive. If you try to open a new file before closing the previous file, a warning will be printed to the console and the previous file will automatically be closed. In addition, any file still open for writing when the archive is closed will automatically be closed before the archive is finalized, as this example demonstrates:","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"using ZipStreams\n\nzipsink(\"new-archive.zip\") do sink\n    f1 = open(sink, \"hello.txt\")\n    write(f1, \"Hello, Julia!\")\n    f2 = open(sink, \"goodbye.txt\")  # issues a warning and closes f1 before opening f2\n    write(f2, \"Good bye, Julia!\")\nend  # automatically closes f2 before closing the archive","category":"page"},{"location":"sinks/#Writing-files-to-an-archive-all-at-once-with-write_file","page":"Writing to Sinks","title":"Writing files to an archive all at once with write_file","text":"","category":"section"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"When you open a file for writing in a ZIP archive using open(sink, filename), writing to the file is done in a streaming fashion with a Data Descriptor written at the end of the file data when it is closed. If you want to write an entire file to the archive at once, you can use the write_file(sink, filename, data) method. This method will write file size and checksum information to the archive in the Local File Header rather than using a Data Descriptor. The advantage to this method is that files written this way are more efficiently read back by a zipsource: when streamed for reading, the Local File Header will report the correct file size. The disadvantages to using this method for writing data are that you need to have all of the data you want to write available at one time and that both the raw data and the compressed data need to fit in memory. Here are some examples using this method for writing files:","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"using ZipStreams\n\nzipsink(\"new-archive.zip\") do sink\n    open(sink, \"hello.txt\") do f1\n        write(f1, \"Hello, Julia!\")  # writes using a Data Descriptor\n    end\nend\n\n\nzipsource(\"new-archive.zip\") do source\n    f = next_file(source)  # works, but is slow to read because the stream has to be checked for a valid Data Descriptor with each read\n    @assert read(f, String) == \"Hello, Julia!\"\nend\n\nzipsink(\"new-archive.zip\") do sink\n    text = \"Hello, Julia!\"\n    write_file(sink, \"hello.txt\", text)  # writes without a Data Descriptor\nend\n\nzipsource(\"new-archive.zip\") do source\n    f = next_file(source)  # is more efficient to read because the file size is known a priori\n    @assert read(f, String) == \"Hello, Julia!\"\nend","category":"page"},{"location":"sinks/#Creating-directories-in-an-archive","page":"Writing to Sinks","title":"Creating directories in an archive","text":"","category":"section"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"Directories within a ZIP archive are nothing more than files with zero length and a name that ends in a forward slash (/). If you try to make a file using open or write_file that has a name ending in /, the method will throw an error. You can, however, make a directory by calling the mkdir and mkpath functions. They work similar to how Base.mkdir and Base.mkpath work: the former will throw an error if all of the parent directories do not exist, while the latter will create the parent directories as needed. Here are examples of these two functions:","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"using ZipStreams\n\nzipsink(\"new-archive.zip\") do sink\n    try\n        f = open(sink, \"file/\")  # fails because files cannot end in '/'\n    catch e\n        @error \"exception caught\" exception=e\n    end\n\n    mkdir(sink, \"dir1/\")  # creates a directory called \"dir1/\" in the root of the archive\n    mkdir(sink, \"dir1/dir2/\")  # creates \"dir2/\" as a subdirectory of \"dir1/\"\n\n    try\n        mkdir(sink, \"dir3/dir4/\")  # fails because mkdir won't create parent directories\n    catch e\n        @error \"exception caught\" exception=e\n    end\n    \n    mkpath(sink, \"dir3/dir4/\")  # creates both \"dir3/\" and \"dir3/dir4/\"\n\n    mkdir(sink, \"dir5\")  # The ending slash will be appended to directory names automatically\nend","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"NOTE: Even on Windows computers, directory names in ZIP files always use forward slash (/) as a directory separator. Backslash characters (\\) are treated as literal backslashes in the directory or filename, so mkdir(sink, \"dir\\\\file\") will create a single file named dir\\file and not a directory.","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"The mkdir and mkpath methods return the number of bytes written to the archive,  including the Local File Header required to define the directory, but excluding the Central Directory Header data (that will be written when the sink is closed).","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"The sink keeps track of which directories have been defined and skips creating directories that already exist, as this example demonstrates:","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"using ZipStreams\n\nzipsink(\"new-archive.zip\") do sink\n    a = mkdir(sink, \"dir1/\")  # returns the number of bytes written to the archive\n    @assert a > 0\n    b = mkdir(sink, \"dir1/\")\n    @assert b == 0  # dir1 already exists, so nothing is written\n    c = mkpath(sink, \"dir1/dir2\")  # dir1 already exists, so do not recreate it\n    d = mkpath(sink, \"dir3/dir4\")  # dir3 has to be created along with dir4\n    @assert d > c  # the second call creates two directories, so more bytes are written\nend","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"Opening a new file in the sink that contains a non-trivial path will throw an error if the parent path does not exist. The keyword argument make_path=true will cause the method to create the parent path as if mkpath were called first:","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"using ZipStreams\n\nzipsink(\"new-archive.zip\") do sink\n    try\n        f = open(sink, \"dir1/file\")  # fails because directory \"dir1/\" does not exist\n    catch e\n        @error \"exception caught\" exception=e\n    end\n    f = open(sink, \"dir1/file\"; make_path=true)  # creates \"dir1/\" first\n    # ...\n    close(f)\nend","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"Relative directory names . or .. are interpreted as directories literally named . or .. and not as relative paths. The root directory of the archive is unnamed, so attempts to create a directory named / will be ignored. Attempting to create an unnamed subdirectory will result in the unnamed subdirectory being ignored (e.g., mkpath(sink, \"dir1//dir2\")  will do the same thing as mkpath(sink, \"dir1/dir2\")). By rule, attempting to make a directory that appears to begin with a Windows drive specifier, even on a non-Windows OS, will throw an error (per 4.4.17 of the APPNOTE document).","category":"page"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"using ZipStreams\n\nzipsink(\"new-archive.zip\") do sink\n    @assert mkpath(sink, \"/\") == 0  # '/' at the beginning is ignored\n    mkpath(sink, \"/dir1\")\n    @assert mkpath(sink, \"dir1\") == 0  # already created with \"/dir1\"\n    \n    mkpath(sink, \"dir1/////dir2\")\n    @assert mkpath(sink, \"dir1/dir2\") == 0  # already created with \"dir1/////dir2\"\n\n    try\n        mkpath(sink, \"c:\\\\dir1\")  # fails because directory appears to start with a drive specifier\n    catch e\n        @error \"exception caught\" exception=e\n    end\n    try\n        mkpath(sink, \"q:dir1\")  # fails for the same reason: the slash at the end doesn't matter\n    catch e\n        @error \"exception caught\" exception=e\n    end\n    try\n        mkpath(sink, \"\\\\\\\\networkshare\\\\dir1\")  # fails because Windows network drives count as drive specifiers\n    catch e\n        @error \"exception caught\" exception=e\n    end\nend","category":"page"},{"location":"sinks/#API","page":"Writing to Sinks","title":"API","text":"","category":"section"},{"location":"sinks/","page":"Writing to Sinks","title":"Writing to Sinks","text":"ZipArchiveSink\nzipsink\nBase.mkdir(::ZipArchiveSink, ::AbstractString)\nBase.mkpath(::ZipArchiveSink, ::AbstractString)\nBase.open(::ZipArchiveSink, ::AbstractString)\nwrite_file","category":"page"},{"location":"sinks/#ZipStreams.ZipArchiveSink","page":"Writing to Sinks","title":"ZipStreams.ZipArchiveSink","text":"ZipArchiveSink\n\nA struct for appending to Zip archives.\n\nZip archives are optimized for appending to the end of the archive. This struct is used in tandem with library functions to keep track of what is appended to a Zip archive so that a proper Central Directory can be written at the end.\n\nUsers should not call the ZipArchiveSink constructor: instead, use the zipsink method to create a new streaming archive.\n\n\n\n\n\n","category":"type"},{"location":"sinks/#ZipStreams.zipsink","page":"Writing to Sinks","title":"ZipStreams.zipsink","text":"zipsink(fname; [keyword arguments]) -> ZipArchiveSink\nzipsink(io; [keyword arguments]) -> ZipArchiveSink\nzipsink(f, args...)\n\nOpen an IO stream of a Zip archive for writing data.\n\nPositional arguments\n\nfname::AbstractString: The name of a Zip archive file to open for writing. Will be created if the file does not exist. If the file does exist, it will be truncated before writing.\nio::IO: An IO object that can be written to. The object will be closed when you call close on the returned object.\nf<:Function: A unary function to which the opened stream will be passed. This method signature allows for do block usage. When called with the signature, the return value of f will be returned to the user.\n\nKeyword arguments\n\nutf8::Bool=true: Encode file names and comments with UTF-8 encoding. If false, follows the Zip standard of treating text as encoded in IBM437 encoding.\ncomment::AbstractString=\"\": A comment to store with the Zip archive. This information is stored in plain text at the end of the archive and does not affect the Zip archive in any other way. The comment is always stored using IBM437 encoding.\n\nnote: Using IO arguments\nPassing an IO object as the first argument will use the object as-is, overwriting from the current position of the stream and writing the Central Directory after closing the stream without truncating the remainder. This use of zipsink is recommended for advanced users only who need to write Zip archives to write-only streams (e.g., network pipes).\n\n\n\n\n\n","category":"function"},{"location":"sinks/#Base.Filesystem.mkdir-Tuple{ZipStreams.ZipArchiveSink, AbstractString}","page":"Writing to Sinks","title":"Base.Filesystem.mkdir","text":"mkdir(archive, path; comment=\"\")\n\nMake a single directory within a ZIP archive.\n\nPath elements in ZIP archives are separated by the forward slash character (/). Backslashes (\\) and dots (. and ..) are treated as literal characters in the directory or file names. The final forward slash character will automatically be added to the directory name when this method is used.\n\nIf any parent directory in the path does not exist, an error will be thrown. Use mkpath to create the entire path at once, including parent paths. Empty directory names (//) will be ignored, as will directories that have already been created in the archive.\n\nThe comment string will be added to the archive's metadata for the directory. It does not affect the stored data in any way.\n\nReturns the number of bytes written to the archive when creating the directory.\n\n\n\n\n\n","category":"method"},{"location":"sinks/#Base.Filesystem.mkpath-Tuple{ZipStreams.ZipArchiveSink, AbstractString}","page":"Writing to Sinks","title":"Base.Filesystem.mkpath","text":"mkpath(archive, path; comment=\"\")\n\nMake a directory and all its parent directories in a ZIP archive.\n\nPath elements in ZIP archives are separated by the forward slash character (/). Backslashes (\\) and dots (. and ..) are treated as literal characters in the directory or file names. The final forward slash character will automatically be added to the directory name when this method is used.\n\nIf any parent directory in the path does not exist, it will be created automatically. Empty directory names (//) will be ignored, as will directories that have already been created in the archive.\n\nThe comment string will be added to the archive's metadata only for the last directory in the path. All other directories created by this method will have no comment. This does not affect the stored data in any way.\n\nReturns the number of bytes written to the archive when creating the entire path.\n\n\n\n\n\n","category":"method"},{"location":"sinks/#Base.open-Tuple{ZipStreams.ZipArchiveSink, AbstractString}","page":"Writing to Sinks","title":"Base.open","text":"open(sink, fname; [keyword arguments]) -> IO\n\nCreate a file within a Zip archive and return a handle for writing.\n\nKeyword arguments\n\ncompression::Union{UInt16,Symbol} = :deflate: Can be one of :deflate, :store, or the associated codes defined by the Zip archive standard (0x0008 or 0x0000, respectively). Determines how the data is compressed when writing to the archive.\nutf8::Bool = true: If true, the file name and comment will be written to the archive metadata encoded in UTF-8 strings, and a flag will be set in the metadata to instruct decompression programs to read these strings as such. If false, the default IBM437 encoding will be used. This does not affect the file data itself.\ncomment::AbstractString = \"\": Comment metadata to add to the archive about the file. This does not affect the file data itself.\nmake_path::Bool = false: If true, any directories in fname will be created first. If false and any directory in the path does not exist, an exception will be thrown.\n\nwarning: Duplicate file names\nThe Zip archive specification does not clearly define what to do if multiple files in the Zip archive share the same name. This method will allow the user to create files with the same name in a single Zip archive, but other software may not behave as expected when reading the archive.\n\n\n\n\n\n","category":"method"},{"location":"sinks/#ZipStreams.write_file","page":"Writing to Sinks","title":"ZipStreams.write_file","text":"write_file(sink, fname, data; [keyword arguments])\n\nArchive data to a new file named fname in an archive sink all at once.\n\nThis is a convenience method that will create a new file in the archive with name fname and write all of data to that file. The data argument can be anything for which the method write(io, data) is defined.\n\nReturns the number of bytes written to the archive.\n\nKeyword arguments are the same as those accepted by open(::ZipArchiveSink, ::AbstractString).\n\nnote: Memory requirements\nThis method reads data into a buffer before writing it to the archive. Both data and the buffered (potentially compressed) copy must be able to fit into memory simultaneously.\n\n\n\n\n\n","category":"function"},{"location":"misc/#Convenience-functions-for-reading-and-writing-archives-from-disk","page":"Other Operations","title":"Convenience functions for reading and writing archives from disk","text":"","category":"section"},{"location":"misc/","page":"Other Operations","title":"Other Operations","text":"CurrentModule = ZipStreams","category":"page"},{"location":"misc/","page":"Other Operations","title":"Other Operations","text":"If you want to simply read an archive from disk and extract some files back to disk, you can use the convenience method unzip_files or unzip_file:","category":"page"},{"location":"misc/","page":"Other Operations","title":"Other Operations","text":"using ZipStreams\n\n# write an archive to disk\narchive_name = tempname()\nzipsink(archive_name) do sink\n    write_file(sink, \"hello.txt\", \"Hello, Julia!\")\n    write_file(sink, \"subdir/goodbye.txt\", \"Goodbye, Julia!\"; make_path=true)\n    write_file(sink, \"test.txt\", \"This is a test.\")\nend\n\n# extract the contents here (\".\")\nunzip_files(archive_name)\n@assert read(\"hello.txt\", String) == \"Hello, Julia!\"\n@assert read(\"subdir/goodbye.txt\", String) == \"Goodbye, Julia!\"\n@assert read(\"test.txt\", String) == \"This is a test.\"\n\n# extract files somewhere else\noutdir = tempdir()\nunzip_files(archive_name; output_path=outdir)\n@assert read(joinpath(output_path, \"hello.txt\"), String) == \"Hello, Julia!\"\n@assert read(joinpath(output_path, \"subdir/goodbye.txt\"), String) == \"Goodbye, Julia!\"\n@assert read(joinpath(output_path, \"test.txt\"), String) == \"This is a test.\"\n\n# extract specific files here, making subdirectories as needed\nunzip_files(archive_name, [\"hello.txt\", \"subdir/goodbye.txt\"])\n@assert read(joinpath(output_path, \"hello.txt\"), String) == \"Hello, Julia!\"\n@assert read(joinpath(output_path, \"subdir/goodbye.txt\"), String) == \"Goodbye, Julia!\"\n\n# extract specific files somewhere else, making the root directory if needed\nunzip_files(archive_name, \"test.txt\"; output_path=\"other/location\", make_path=true)\n@assert read(\"other/location/test.txt\", String) == \"This is a test.\"","category":"page"},{"location":"misc/","page":"Other Operations","title":"Other Operations","text":"If you want to store files from disk to a new archive, you can use the zip_files or zip_file method:","category":"page"},{"location":"misc/","page":"Other Operations","title":"Other Operations","text":"using ZipStreams\n\n# make some fake files to compress\ndir = mktempdir()\npath1 = tempname(dir)\nwrite(path1, \"Hello, Julia!\")\npath2 = tempname(dir)\nwrite(path2, \"Goodbye, Julia!\")\n\n# Archive the files\narchive_name = tempname(dir)\nzip_files(archive_name, [path1, path2])","category":"page"},{"location":"misc/#API","page":"Other Operations","title":"API","text":"","category":"section"},{"location":"misc/","page":"Other Operations","title":"Other Operations","text":"unzip_files\nzip_files","category":"page"},{"location":"misc/#ZipStreams.unzip_files","page":"Other Operations","title":"ZipStreams.unzip_files","text":"unzip_files(archive; output_path::AbstractString=\".\", make_path::Bool=false)\nunzip_files(archive, files; [keyword_args])\n\nUnzip files from archive. If files is not given, extract all files.\n\nThis method opens the archive and iterates through the archived files, writing them to disk to the directory tree rooted at output_path. If make_path is true and output_path does not exist, it will be created.\n\nSee zipsource and next_file for more information about how the files are read from the archive.\n\n\n\n\n\n","category":"function"},{"location":"misc/#ZipStreams.zip_files","page":"Other Operations","title":"ZipStreams.zip_files","text":"zip_files(out_filename, files; [keyword_args])\nzip_files(out_filename, dir; recurse_directories=false, [keyword_args])\n\nCreate an archive from files on disk.\n\nThe archive out_filename will be created using the zipsink method with the given keyword arguments. in_filename can be a single path or a vector of multiple paths on disk. The files will be written in the archive with paths matching the closest common relative path between the current directory (\".\") and the full path of the file, so if archive_filename is \"/a/b/archive.zip\" and one of files is \"/a/c/file\", then the file will be witten with the path \"c/file\".\n\nIf dir is a directory and recurse_directories is true, then all files and directories found when traversing the directory will be added to the archive. If recurse_directories is false (the default), then subdirectories of dir will not be traversed.\n\nAll files are written to the archive using the default arguments specified by open(zipsink, fn). See open(::ZipArchiveSink, ::AbstractString) for more information.\n\nSee zipsink for more information about the optional keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"info/#Printing-info-about-ZIP-archives","page":"Printing Information","title":"Printing info about ZIP archives","text":"","category":"section"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"CurrentModule = ZipStreams","category":"page"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"You can print information about a ZIP archive or a file within a ZIP archive to the terminal (or any IO object) with the info method. The format of the information displayed for each file is similar to the short format produced by ZipInfo. In general, the output has the following format:","category":"page"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"TTTT UUUUUUUU ZZZ LLL CCCCCCCC XXXX dd-mmm-yy hh:mm:ss 0xSSSSSSSS NAME","category":"page"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"The definitions of these fields are, in order:","category":"page"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"TTTT: Either the string \"file\" or \"dir \", signifying what kind of entry it is;\nUUUUUUUU: The uncompressed size of the file in bytes;\nZZZ: Either the string \"z64\" or \"---\", signifying that the Local File Header uses the Zip64 format;\nLLL: Either the string \"lhx\" or \"---\", signifying that a Data Descriptor is used;\nCCCCCCCC: The compressed size of the file in bytes;\nXXXX: The compression method used to compress the data;\ndd-mmm-yy hh:mm:ss: The creation date and time of the file;\n0xSSSSSSSS: The CRC-32 checksum of the compressed data as a hexadecimal number;\nNAME: The name of the entry in the Local File Header.","category":"page"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"If called on an archive source, info about all of the archived entities read from the source so far is printed in archive order, along with status information about how much has been read from the archive so far, whether or not the EOF has been reached, and statistics about the number and size of the entries.","category":"page"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"The first call to info in this example reports nothing has been read yet:","category":"page"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"DocTestFilters = [r\"\\d{2}-[A-Z][a-z]{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\"]","category":"page"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"using ZipStreams\n\nbuffer = IOBuffer()\nzipsink(buffer) do sink\n    write_file(sink, \"hello.txt\", \"Hello, Julia!\")\n    write_file(sink, \"subdir/goodbye.txt\", \"Goodbye, Julia!\"; compression=:store, make_path=true)\nend\n\nseekstart(buffer)\nzipsource(buffer) do source\n    info(source)\nend\n\n# output\n\nZIP archive source stream data after reading 0 B, number of entries: 0","category":"page"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"After reading all of the data in the archive using vialidate, a call to info reports information about the entities read:","category":"page"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"seekstart(buffer)\nzipsource(buffer) do source\n    validate(source)\n    info(source)\nend\n\n# output\n\nZIP archive source stream data after reading 348 B (EOF reached), number of entries: 3\nfile       13 --- ---       15 defl 02-Nov-22 00:58:36 0xb2284bb4 hello.txt\ndir         0 --- ---        0 stor 02-Nov-22 00:58:36 0x00000000 subdir/\nfile       15 --- ---       15 stor 02-Nov-22 00:58:36 0xb24bab9f subdir/goodbye.txt\n2 files, 28 B uncompressed, 30 B compressed","category":"page"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"DocTestFilters = nothing","category":"page"},{"location":"info/#API","page":"Printing Information","title":"API","text":"","category":"section"},{"location":"info/","page":"Printing Information","title":"Printing Information","text":"info","category":"page"},{"location":"info/#ZipStreams.info","page":"Printing Information","title":"ZipStreams.info","text":"info([io::IO = stdout], zip)\n\nPrint information about a ZIP archive or file stream.\n\n\n\n\n\n","category":"function"},{"location":"sources/#Sources:-Read-only-Streams-of-Data","page":"Reading from Sources","title":"Sources: Read-only Streams of Data","text":"","category":"section"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"CurrentModule = ZipStreams","category":"page"},{"location":"sources/#Reading-archives-with-zipsource","page":"Reading from Sources","title":"Reading archives with zipsource","text":"","category":"section"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"You can wrap any Julia readable IO object with the zipsource function. The returned object can be iterated to read archived files in archive order. Information about each file is stored in the .info property of the object returned from the iterator. The object returned from the iterator is readable like any standard Julia IO object, but it is not writable.","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"Here are some examples:","category":"page"},{"location":"sources/#Iterating-through-files-from-an-archive-on-disk","page":"Reading from Sources","title":"Iterating through files from an archive on disk","text":"","category":"section"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"This is perhaps the most common way to work with ZIP archives: reading them from disk and doing things with the contained files. Because zipsource reads from the beginning of the file to the end, you can only iterate through files in archive order and cannot randomly access files. Here is an example of how to work with this kind of file iteration:","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"using ZipStreams\n\n# open an archive from an IO object\nopen(\"archive.zip\") do io\n    zs = zipsource(io)\n\n    # iterate through files\n    for f in zs\n        \n        # get information about each file from the .info property\n        println(f.info.name)\n\n        # read from the file just like any other IO object\n        println(readline(f))\n        \n        println(read(f, String))\n    end\nend","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"You can use the next_file method to access the next file in the archive without iterating in a loop. The method returns nothing if it reaches the end of the archive.","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"using ZipStreams\n\nopen(\"archive.zip\") do io\n    zs = zipsource(io)\n    f = next_file(zs) # the first file in the archive, or nothing if there are no files archived\n    # ...\n    f = next_file(zs) # the next file in the archive, or nothing if there was only one file\n    # ...\nend","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"Because reading ZIP files from an archive on disk is a common use case, a convenience method taking a file name argument is provided:","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"using ZipStreams\n\nzs = zipsource(\"archive.zip\") # Note: the caller is responsible for closing this to free the file handle\n# ... \nclose(zs)","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"In addition, a method that takes as its first argument a unary function is included so that users can manage the lifetime of any file handles opened by zipsource in an open() do x ... end block:","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"using ZipStreams\n\nzipsource(\"archive.zip\") do zs\n    # ...\nend # file handle is automatically closed at the end of the block","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"The same method is defined for IO arguments, but it works slightly differently: the object passed is not closed when the block ends. It assumes that the caller is responsible for the IO object's lifetime. However, manually calling close on the source will always close the wrapped IO object. Here is an example:","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"using ZipStreams\n\nio = open(\"archive.zip\")\nzipsource(io) do zs\n    # ...\nend\n@assert isopen(io) == true\n\nseekstart(io)\nzipsource(io) do zs\n    # ...\n    close(zs) # called manually\nend\n@assert isopen(io) == false","category":"page"},{"location":"sources/#Verifying-the-content-of-ZIP-archives","page":"Reading from Sources","title":"Verifying the content of ZIP archives","text":"","category":"section"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"A ZIP archive stores file sizes and checksums in two of three locations: one of  either immediately before the archived file data (in the \"Local File Header\") or immediately after the archived file data (in the \"Data Descriptor\"), and always at the end of the file (in the \"Central Directory\"). Because the Central Directory is considered the ground truth, the Local File Header and Data Descriptor may report inaccurate values. To verify that the content of the file matches the values in the Local File Header, use the validate method on the archived file. To verify that all file content in the archive matches the values in the Central Directory, use the validate method on the archive itself. These methods will throw an error if they detect any inconsistencies.","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"For example, to validate the data in a single file stored in the archive:","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"using ZipStreams\n\nzipsource(\"archive.zip\") do zs\n    f = next_file(zs)\n    validate(f) # throws if there is an inconsistency\nend","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"To validate the data in all of the remaining files in the archive:","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"using ZipStreams\n\nio = open(\"archive.zip\")\nzipsource(io) do zs\n    validate(zs) # validate all files and the archive itself\nend\n\nseekstart(io)\nzipsource(io) do zs\n    f = next_file(zs) # read the first file\n    validate(zs) # validate all files except the first!\nend\n\nclose(io)","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"The validate methods consume the data in the source and return vectors of raw bytes. When called on an archived file, it returns a single Vector{UInt8}. When called on the archive itself, it returns a Vector{Vector{UInt8}} containing the remaining unread file data in archive order, excluding any files that have already been read by iterating or with `nextfile`_.","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"using ZipStreams\n\nzs = zipsource(\"archive.zip\")\nf1 = next_file(zs)\ndata1 = validate(f1) # contains all the file data as raw bytes\n@assert typeof(data1) == Vector{UInt8}\nclose(zs)\n\nzs = zipsource(\"archive.zip\")\nf2 = next_file(zs)\nprintln(readline(f2)) # read a line off the file first\ndata2 = validate(f2) # contains the remaining file data excluding the first line!\n@assert typeof(data2) == Vector{UInt8}\n@assert sizeof(data2) < sizeof(data1)\nclose(zs)\n\nzs = zipsource(\"archive.zip\")\nall_data = validate(zs) # returns a Vector{Vector{UInt8}} of all remaining files\n@assert all_data[1] == data1\nclose(zs)","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"Note that these methods consume the data in the file or archive, as demonstrated in this example:","category":"page"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"using ZipStreams\n\nzs = zipsource(\"archive.zip\")\nvalidate(zs)\n@assert eof(zs) == true","category":"page"},{"location":"sources/#API","page":"Reading from Sources","title":"API","text":"","category":"section"},{"location":"sources/","page":"Reading from Sources","title":"Reading from Sources","text":"ZipArchiveSource\nzipsource\nnext_file\nvalidate","category":"page"},{"location":"sources/#ZipStreams.ZipArchiveSource","page":"Reading from Sources","title":"ZipStreams.ZipArchiveSource","text":"ZipArchiveSource\n\nA read-only lazy streamable representation of a Zip archive.\n\nThe authoritative record of files present in a Zip archive is stored in the Central Directory at the end of the archive. This allows for easy appending of new files to the archive by overwriting the Central Directory and adding a new Central Directory with the updated contents afterward. It also allows for easy deletion of files from the old archive by overwriting the Central Directory with the updated contents and relying on compliant Zip archive extraction programs ignoring the actual bytes in the file and only trusting the new Central Directory.\n\nUnfortunately, this choice makes reading the contents of a Zip archive sub-optimal, especially over streaming IO interfaces like networks, where seeking to the end of the file requires reading all of the file's contents first.\n\nHowever, this package chooses not to be a compliant Zip archive reader. By ignoring the Central Directory, one can begin extracting data from a Zip archive immediately upon reading the first Local File Header record it sees in the stream, greatly reducing latency to first read on large files, and also reducing the amount of data necessary to cache on disk or in memory.\n\nA ZipArchiveSource is a wapper around an IO object that allows the user to extract files as they are read from the stream instead of waiting to read the file information from the Central Directory at the end of the stream.\n\nZipArchiveSource objects can be iterated. Each iteration returns an IO object that will lazily extract (and decompress) file data from the archive.\n\nInformation about each file in the archive is stored in the directory property of the struct as the file is read from the archive.\n\nCreate ZipArchiveSource objects using the zipsource function.\n\n\n\n\n\n","category":"type"},{"location":"sources/#ZipStreams.zipsource","page":"Reading from Sources","title":"ZipStreams.zipsource","text":"zipsource(io)\nzipsource(f, io)\n\nCreate a read-only lazy streamable representation of a Zip archive.\n\nThe first form returns a ZipArchiveSource wrapped around io that allows the user to extract files as they are read from the stream by iterating over the returned object. io can be an object that inherits from Base.IO (technically only requiring read, eof, isopen, close, and bytesavailable to be defined) or an AbstractString file name, which will open the file in read-only mode and wrap that IOStream.\n\nThe second form takes a unary function as the first argument. The constructed ZipArchiveSource object will be passed to the function and the results of the function will be returned to the user. This allows compatability with do blocks. If io is an AbstractString file name, the file will be automatically closed when the block exits. If io is a Base.IO object as described above, it will not be closed when the block exits, allowing the caller to have control over the lifetime of the argument.\n\nwarning: Reading before knowing where files end can be dangerous!\nThe Central Directory in the Zip archive is the authoritative source for file locations, compressed and uncompressed sizes, and CRC-32 checksums. A Local File Header can lie about this information, leading to improper file extraction.  We highly recommend that users validate the file contents against the Central Directory using the validate method before beginning to trust the extracted files from uncontrolled sources.\n\n\n\n\n\n","category":"function"},{"location":"sources/#ZipStreams.next_file","page":"Reading from Sources","title":"ZipStreams.next_file","text":"next_file(archive) => Union{IO, Nothing}\n\nRead the next file in the archive and return a readable IO object or nothing.\n\nThis is the same as calling first(iterate(archive)).\n\n\n\n\n\n","category":"function"},{"location":"sources/#ZipStreams.validate","page":"Reading from Sources","title":"ZipStreams.validate","text":"validate(zf::ZipFileSource)\n\nValidate that the contents read from an archived file match the information stored in the Local File Header and return the data read.\n\nIf the contents of the file do not match the information in the Local File Header, the method will throw an error. The method checks that the compressed and uncompressed file sizes match what is in the header, and that the CRC-32 of the compressed data matches what is reported in the header.\n\nThis method will return the remainder of the raw file data that has not yet been read from the archive as a Vector{UInt8}.\n\n\n\n\n\nvalidate(source::ZipArchiveSource)\n\nValidate the files in the archive source against the Central Directory at the end of the archive and return all data read as a vector of byte vectors (one per file).\n\nThis method consumes all the remaining data in the source stream of source and throws an exception if the file information read does not match the information in the Central Directory. Files that have already been consumed prior to calling this method will still be validated, even if their contents are not returned.\n\nSee also validate(::ZipFileSource).\n\n\n\n\n\n","category":"function"},{"location":"#ZipStreams","page":"Overview","title":"ZipStreams","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"A Julia package to read and write ZIP archives from read-only or write-only streams by ignoring standards just a little bit.","category":"page"},{"location":"#Synopsis","page":"Overview","title":"Synopsis","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"using ZipStreams\n\nzipsink(\"archive.zip\") do sink     # context management of sinks with \"do\" syntax\n    open(sink, \"hello.txt\") do f   # context management of files with \"do\" syntax\n        write(f, \"Hello, Julia!\")  # write just like you write to any IO object\n    end\nend\n\nzipsource(\"archive.zip\") do source   # context management of sources with \"do\" syntax\n    for f in source                  # iterate through files in an archive\n        println(f.info.name)         # \"hello.txt\"\n        read_data = read(String, f)  # read just like you read from any IO object\n        println(read_data)           # \"Hello, Julia!\"\n    end\nend","category":"page"},{"location":"#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"\"There are three ways to do things: the right way, the wrong way, and the Max Power way.\"-Homer from The Simpsons, season 10, episode 13: \"Homer to the Max\"","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"ZIP archives are optimized for appending and deleting operations. This is because the canonical source of information for what is stored in a ZIP archive, the \"Central Directory\", is written at the very end of the archive. Users who want to append a file to the archive can overwrite the Central Directory with new file data, then append an updated Central Directory afterward, and nothing else in the file has to be touched. Likewise, users who want to delete files in the archive only have to change the entries in the Central Directory: readers that conform to the standard described in the PKWARE APPNOTE file will ignore the files that are no longer listed.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"This design choice means that standards-conformant readers like ZipFile.jl cannot know what files are stored in a ZIP archive until they read to the very end of the archive. While this is not typically a problem on modern SSD-based storage, where random file access is fast, it is a major limitation on stream-based file transfer systems like networks, where readers typically have no choice but to read an entire file from beginning to end in order. And again, this is not a problem for archives with sizes on the order of megabytes, but standard ZIP archives can be as large as 4GB, which can easily overwhelm systems with limited memory or storage like embedded systems or cloud-based micro-instances. To make matters worse, ZIP64 archives can be up to 16 EB (2^64 bytes) in size, which can easily overwhelm even the largest of modern supercomputers.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"However, the ZIP archive specification also requires a \"Local File Header\" to precede the (possibly compressed) file data of every file in the archive. The Local File Header contains enough information to allow a reader to extract the file and perform simple error checking as long as three conditions are met:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"The information in the Local File Header is correctly specified. The Central Directory is the canonical source of information, so the Local File Header could be lying.\nThe Central Directory is not encrypted. File sizes and checksum values are masked from the Local File Header if the Central Directory is encrypted, so it is impossible to know where the file ends and the next one begins.\nThe file is not stored with a \"Data Descriptor\" (general purpose flag 3). As with encryption, files that are stored with a Data Descriptor have masked file sizes and checksums in the Local File Header. This format is typically used only when the archive is written in a streaming fashion.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"All this being said, most users will never see ZIP files that cannot be extracted exclusively using Local File Header information.","category":"page"},{"location":"#About-files-written-with-Data-Descriptors","page":"Overview","title":"About files written with Data Descriptors","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"When a file is streamed to an archive, the final size of the file may not be knowable until the last byte is writtenâ€“this is especially true if the file is being compressed while it is being streamed. Files streamed in this way use a Data Descriptor, appended immediately after the file data, to record the CRC-32 checksum and compressed and uncompressed sizes. Files written in this way can be read in a streaming way as well, but only if the data being read is buffered, and only if the file was written with the optional Data Descriptor signature as described in section 4.3.9.3 of the PKWARE APPNOTE file.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"When reading a file that signals in the Local File Header that it uses a Data Descriptor, this package will check for a valid Data Descriptor on every read from the stream. This is the only way the package can determine if a file written with a Data Descriptor has been completely consumed from the archive source. This makes reading files using Data Descriptors much less efficient than reading files that use Local File Headers to specify lengths, where the package only has to count bytes to know if it has completely consumed the file from the archive source.","category":"page"},{"location":"#DO-NOT-BLINDLY-TRUST-ZIP-ARCHIVES","page":"Overview","title":"DO NOT BLINDLY TRUST ZIP ARCHIVES","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"By ignoring the Central Directory, this module makes no guarantees that what you get out of the ZIP archive matches what you or anyone else put into it. The code is tested against ZIP archives generated by various writers, but there are corner cases, ambiguities in the standard, and even pathological ZIP files in the wild that may silently break this package.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Bart: \"Isn't that the wrong way?\"Homer: \"Yeah, but faster!\"-The Simpsons, season 10, episode 13: \"Homer to the Max\"","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"You have been warned!","category":"page"},{"location":"#Installation","page":"Overview","title":"Installation","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Install via the Julia package manager, Pkg.add(\"ZipStreams\").","category":"page"},{"location":"#Terminology:-Archives-and-Files,-Sources-and-Sinks","page":"Overview","title":"Terminology: Archives and Files, Sources and Sinks","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"To avoid ambiguity, this package tries to use the following terms consistently throughout type names, function names, and documentation:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"File: A File is a named sequence of zero or more bytes that represents a distinct collection of data within an Archive. According to the ZIP standard, a File is always preceded by a Local File Header and may have a Data Descriptor following the File's contents. The contents of the File may be compressed within the Archive.\nDirectory: A Directory is a named structure within an Archive that exists for organizational purposes only. A Directory meets the definition of File with the additional conditions that it always has size zero, it never has a Data Descriptor following it, and has a name that always ends in a forward slash character (/).\nEntity: An Entity is either a File or a Directory.\nArchive: An Archive is a sequence of bytes that represents zero or more separate Entities. According to the ZIP standard, an Archive is a series of Entities followed by a Central Directory which describes the Entities.\nSource: A Source is an object that can be read as a sequence of bytes from beginning to end. A Source does not necessarily implement random access or seek operations, nor does it necessarily support write operations.\nSink: A Sink is an object to which a sequence of bytes can be written. A Sink does not necessarily implement random access or seek operations, nor does it necessarily support read operations.","category":"page"},{"location":"#Notes","page":"Overview","title":"Notes","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"This package was inspired by frustrations with using standards-compliant ZIP archive reader/writers like ZipFile.jl on streams of data from a network source. That's not to say ZipFile.jl is badâ€“on the contrary, it is way more standards-compliant than this package ever intends to be! As you can see from the history of this repository, much of the work here started as a fork of that package. Because of that, I am grateful to Fazlul Shahriar for programming and making available ZipFile.jl.","category":"page"},{"location":"pathological/#Making-pathological-files-in-ZIP-archives","page":"Pathological Files","title":"Making pathological files in ZIP archives","text":"","category":"section"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"CurrentModule = ZipStreams","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"A File that uses a Data Descriptor can easily trick this module if care is taken in the construction of the data that goes into the File. First, write some data to a File sink:","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"sink = zipsink(\"pathological.zip\")\nzf = open(sink, \"file.txt\"; compression=:store)\ndata = \"Hello, Julia!\"\n\nwrite(zf, data)","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"Second, write the Data Descriptor header to the File (in little-endian format):","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"write(zf, htol(ZipStreams.SIG_DATA_DESCRIPTOR))","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"Third, write the CSC-32 checksum of the original data to the File (again, in little-endian format):","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"write(zf, htol(ZipStreams.crc32(data)))","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"Finally, write the compressed and uncompressed sizes of the data to the File (you guessed it: in little-endian format). This is made easier by using the compression=:store keyword argument when opening the File for writing. Because the default File format is Zip64 (keyword argument zip64=true), you need to write these as UInt64 integers (if you set zip64=false, write these as UInt32 instead):","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"write(zf, hotl(sizeof(data) % UInt64)) # compressed size\nwrite(zf, hotl(sizeof(data) % UInt64)) # uncompressed size","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"Now write whatever you want after that:","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"write(zf, \"Goodbye, Julia!\")\nclose(zf)\nclose(sink)","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"When you read the Archive back, you'll find that the stream reader will read up to the fake Data Descriptor that you wrote and ignore the additional data that you wrote afterward:","category":"page"},{"location":"pathological/","page":"Pathological Files","title":"Pathological Files","text":"zipsource(\"pathological.zip\") do source\n    for zf in source\n        println(read(zf, String))\n    end\nend\n\n# output\n\nHello, Julia!","category":"page"}]
}
